{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ehsan Shaghaei\n",
    "Nov 2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fa68ceaeb90>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import gym\n",
    "import pickle\n",
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "\n",
    "from tensorflow.keras import layers, optimizers\n",
    "from IPython.display import HTML, display\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from collections import deque\n",
    "from statistics import mean\n",
    "\n",
    "seed = 111\n",
    "\n",
    "tf.random.set_seed(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "\n",
    "# For Kaggle\n",
    "import os\n",
    "os.environ[\"SDL_VIDEODRIVER\"] = \"dummy\"\n",
    "\n",
    "# Lunar Lander environment initialization\n",
    "env = gym.make(\"LunarLander-v2\",render_mode='rgb_array')\n",
    "obs = env.reset()\n",
    "image = env.render()\n",
    "plt.imshow(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I chose to play with LunarLander Environment on openAI.\n",
    "\n",
    "In this environment, Landing pad is always at coordinates (0,0). Coordinates are the first\n",
    "two numbers in state vector. Reward for moving from the top of the screen\n",
    "to landing pad and zero speed is about 100..140 points. If lander moves\n",
    "away from landing pad it loses reward back. Episode finishes if the lander\n",
    "crashes or comes to rest, receiving additional -100 or +100 points.\n",
    "Each leg ground contact is +10. Firing main engine is -0.3 points each frame.\n",
    "Solved is 200 points. Landing outside landing pad is possible. Fuel is\n",
    "infinite, so an agent can learn to fly and then land on its first attempt.\n",
    "Four discrete actions available: do nothing, fire left orientation engine,\n",
    "fire main engine, fire right orientation engine.\n",
    "\n",
    "\n",
    "I evalute different methods of reinforcement learning through this journey."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Q-Learning for disceretiesd environment\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_19 (Dense)            (None, 64)                576       \n",
      "                                                                 \n",
      " prunable (Dense)            (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_20 (Dense)            (None, 4)                 260       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,996\n",
      "Trainable params: 4,996\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "N_STATES = env.observation_space.shape[0]\n",
    "N_ACTIONS = env.action_space.n\n",
    "\n",
    "def create_model():\n",
    "    \"\"\"Construct the critic network with q-values per action as output\"\"\"\n",
    "    model = keras.Sequential([\n",
    "        layers.Input(shape=(N_STATES)),\n",
    "        layers.Dense(64, activation=\"relu\"),\n",
    "        layers.Dense(64, activation=\"relu\", name='prunable'),\n",
    "        layers.Dense(N_ACTIONS, activation='linear')\n",
    "    ])\n",
    "    \n",
    "    model.compile(optimizer=optimizers.Adam(.001), loss='mse')\n",
    "\n",
    "    return model\n",
    "\n",
    "model = create_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "St\n",
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_21 (Dense)            (None, 512)               4608      \n",
      "                                                                 \n",
      " dense_22 (Dense)            (None, 256)               131328    \n",
      "                                                                 \n",
      " dense_23 (Dense)            (None, 4)                 1028      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 136,964\n",
      "Trainable params: 136,964\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ahuratus/.local/lib/python3.10/site-packages/keras/optimizers/optimizer_v2/adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 2 into shape (1,8)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [39], line 325\u001b[0m\n\u001b[1;32m    323\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mSt\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    324\u001b[0m model \u001b[39m=\u001b[39m DQN(env, lr, gamma, epsilon, epsilon_decay)\n\u001b[0;32m--> 325\u001b[0m model\u001b[39m.\u001b[39;49mtrain(training_episodes, \u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m    327\u001b[0m \u001b[39m# Save Everything\u001b[39;00m\n\u001b[1;32m    328\u001b[0m save_dir \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39msaved_models\u001b[39m\u001b[39m\"\u001b[39m\n",
      "Cell \u001b[0;32mIn [39], line 100\u001b[0m, in \u001b[0;36mDQN.train\u001b[0;34m(self, num_episodes, can_stop)\u001b[0m\n\u001b[1;32m     98\u001b[0m reward_for_episode \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m     99\u001b[0m num_steps \u001b[39m=\u001b[39m \u001b[39m1000\u001b[39m\n\u001b[0;32m--> 100\u001b[0m state \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mreshape(state, [\u001b[39m1\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnum_observation_space])\n\u001b[1;32m    101\u001b[0m \u001b[39mfor\u001b[39;00m step \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(num_steps):\n\u001b[1;32m    102\u001b[0m     env\u001b[39m.\u001b[39mrender()\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mreshape\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/numpy/core/fromnumeric.py:298\u001b[0m, in \u001b[0;36mreshape\u001b[0;34m(a, newshape, order)\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[39m@array_function_dispatch\u001b[39m(_reshape_dispatcher)\n\u001b[1;32m    199\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mreshape\u001b[39m(a, newshape, order\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mC\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m    200\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    201\u001b[0m \u001b[39m    Gives a new shape to an array without changing its data.\u001b[39;00m\n\u001b[1;32m    202\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    296\u001b[0m \u001b[39m           [5, 6]])\u001b[39;00m\n\u001b[1;32m    297\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 298\u001b[0m     \u001b[39mreturn\u001b[39;00m _wrapfunc(a, \u001b[39m'\u001b[39;49m\u001b[39mreshape\u001b[39;49m\u001b[39m'\u001b[39;49m, newshape, order\u001b[39m=\u001b[39;49morder)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/numpy/core/fromnumeric.py:54\u001b[0m, in \u001b[0;36m_wrapfunc\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     52\u001b[0m bound \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(obj, method, \u001b[39mNone\u001b[39;00m)\n\u001b[1;32m     53\u001b[0m \u001b[39mif\u001b[39;00m bound \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m---> 54\u001b[0m     \u001b[39mreturn\u001b[39;00m _wrapit(obj, method, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m     56\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     57\u001b[0m     \u001b[39mreturn\u001b[39;00m bound(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/numpy/core/fromnumeric.py:43\u001b[0m, in \u001b[0;36m_wrapit\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m:\n\u001b[1;32m     42\u001b[0m     wrap \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m---> 43\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39;49m(asarray(obj), method)(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m     44\u001b[0m \u001b[39mif\u001b[39;00m wrap:\n\u001b[1;32m     45\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(result, mu\u001b[39m.\u001b[39mndarray):\n",
      "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 2 into shape (1,8)"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import deque\n",
    "import random\n",
    "\n",
    "\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.activations import relu, linear\n",
    "from keras.optimizers import Adam\n",
    "from keras.losses import mean_squared_error\n",
    "from keras.models import load_model\n",
    "\n",
    "\n",
    "import pickle\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "class DQN:\n",
    "    def __init__(self, env, lr, gamma, epsilon, epsilon_decay):\n",
    "\n",
    "        self.env = env\n",
    "        self.action_space = env.action_space\n",
    "        self.observation_space = env.observation_space\n",
    "        self.counter = 0\n",
    "\n",
    "        self.lr = lr\n",
    "        self.gamma = gamma\n",
    "        self.epsilon = epsilon\n",
    "        self.epsilon_decay = epsilon_decay\n",
    "        self.rewards_list = []\n",
    "\n",
    "        self.replay_memory_buffer = deque(maxlen=500000)\n",
    "        self.batch_size = 64\n",
    "        self.epsilon_min = 0.01\n",
    "        self.num_action_space = self.action_space.n\n",
    "        self.num_observation_space = env.observation_space.shape[0]\n",
    "        self.model = self.initialize_model()\n",
    "\n",
    "    def initialize_model(self):\n",
    "        model = Sequential()\n",
    "        model.add(Dense(512, input_dim=self.num_observation_space, activation=relu))\n",
    "        model.add(Dense(256, activation=relu))\n",
    "        model.add(Dense(self.num_action_space, activation=linear))\n",
    "\n",
    "        # Compile the model\n",
    "        model.compile(loss=mean_squared_error,optimizer=Adam(lr=self.lr))\n",
    "        print(model.summary())\n",
    "        return model\n",
    "\n",
    "    def get_action(self, state):\n",
    "        if np.random.rand() < self.epsilon:\n",
    "            return random.randrange(self.num_action_space)\n",
    "\n",
    "        predicted_actions = self.model.predict(state)\n",
    "        return np.argmax(predicted_actions[0])\n",
    "\n",
    "    def add_to_replay_memory(self, state, action, reward, next_state, done):\n",
    "        self.replay_memory_buffer.append((state, action, reward, next_state, done))\n",
    "\n",
    "    def learn_and_update_weights_by_reply(self):\n",
    "\n",
    "        # replay_memory_buffer size check\n",
    "        if len(self.replay_memory_buffer) < self.batch_size or self.counter != 0:\n",
    "            return\n",
    "\n",
    "        # Early Stopping\n",
    "        if np.mean(self.rewards_list[-10:]) > 180:\n",
    "            return\n",
    "\n",
    "        random_sample = self.get_random_sample_from_replay_mem()\n",
    "        states, actions, rewards, next_states, done_list = self.get_attribues_from_sample(random_sample)\n",
    "        targets = rewards + self.gamma * (np.amax(self.model.predict_on_batch(next_states), axis=1)) * (1 - done_list)\n",
    "        target_vec = self.model.predict_on_batch(states)\n",
    "        indexes = np.array([i for i in range(self.batch_size)])\n",
    "        target_vec[[indexes], [actions]] = targets\n",
    "\n",
    "        self.model.fit(states, target_vec, epochs=1, verbose=0)\n",
    "\n",
    "    def get_attribues_from_sample(self, random_sample):\n",
    "        states = np.array([i[0] for i in random_sample])\n",
    "        actions = np.array([i[1] for i in random_sample])\n",
    "        rewards = np.array([i[2] for i in random_sample])\n",
    "        next_states = np.array([i[3] for i in random_sample])\n",
    "        done_list = np.array([i[4] for i in random_sample])\n",
    "        states = np.squeeze(states)\n",
    "        next_states = np.squeeze(next_states)\n",
    "        return np.squeeze(states), actions, rewards, next_states, done_list\n",
    "\n",
    "    def get_random_sample_from_replay_mem(self):\n",
    "        random_sample = random.sample(self.replay_memory_buffer, self.batch_size)\n",
    "        return random_sample\n",
    "\n",
    "    def train(self, num_episodes=2000, can_stop=True):\n",
    "        for episode in range(num_episodes):\n",
    "            state = env.reset()\n",
    "            reward_for_episode = 0\n",
    "            num_steps = 1000\n",
    "            state = np.reshape(state, [1, self.num_observation_space])\n",
    "            for step in range(num_steps):\n",
    "                env.render()\n",
    "                received_action = self.get_action(state)\n",
    "                # print(\"received_action:\", received_action)\n",
    "                next_state, reward, done, info = env.step(received_action)\n",
    "                next_state = np.reshape(next_state, [1, self.num_observation_space])\n",
    "                # Store the experience in replay memory\n",
    "                self.add_to_replay_memory(state, received_action, reward, next_state, done)\n",
    "                # add up rewards\n",
    "                reward_for_episode += reward\n",
    "                state = next_state\n",
    "                self.update_counter()\n",
    "                self.learn_and_update_weights_by_reply()\n",
    "\n",
    "                if done:\n",
    "                    break\n",
    "            self.rewards_list.append(reward_for_episode)\n",
    "\n",
    "            # Decay the epsilon after each experience completion\n",
    "            if self.epsilon > self.epsilon_min:\n",
    "                self.epsilon *= self.epsilon_decay\n",
    "\n",
    "            # Check for breaking condition\n",
    "            last_rewards_mean = np.mean(self.rewards_list[-100:])\n",
    "            if last_rewards_mean > 200 and can_stop:\n",
    "                print(\"DQN Training Complete...\")\n",
    "                break\n",
    "            print(episode, \"\\t: Episode || Reward: \",reward_for_episode, \"\\t|| Average Reward: \",last_rewards_mean, \"\\t epsilon: \", self.epsilon )\n",
    "\n",
    "    def update_counter(self):\n",
    "        self.counter += 1\n",
    "        step_size = 5\n",
    "        self.counter = self.counter % step_size\n",
    "\n",
    "    def save(self, name):\n",
    "        self.model.save(name)\n",
    "\n",
    "\n",
    "def test_already_trained_model(trained_model):\n",
    "    rewards_list = []\n",
    "    num_test_episode = 100\n",
    "    env = gym.make(\"LunarLander-v2\")\n",
    "    print(\"Starting Testing of the trained model...\")\n",
    "\n",
    "    step_count = 1000\n",
    "\n",
    "    for test_episode in range(num_test_episode):\n",
    "        current_state = env.reset()\n",
    "        num_observation_space = env.observation_space.shape[0]\n",
    "        current_state = np.reshape(current_state, [1, num_observation_space])\n",
    "        reward_for_episode = 0\n",
    "        for step in range(step_count):\n",
    "            env.render()\n",
    "            selected_action = np.argmax(trained_model.predict(current_state)[0])\n",
    "            new_state, reward, done, info = env.step(selected_action)\n",
    "            new_state = np.reshape(new_state, [1, num_observation_space])\n",
    "            current_state = new_state\n",
    "            reward_for_episode += reward\n",
    "            if done:\n",
    "                break\n",
    "        rewards_list.append(reward_for_episode)\n",
    "        print(test_episode, \"\\t: Episode || Reward: \", reward_for_episode)\n",
    "\n",
    "    return rewards_list\n",
    "\n",
    "\n",
    "def plot_df(df, chart_name, title, x_axis_label, y_axis_label):\n",
    "    plt.rcParams.update({'font.size': 17})\n",
    "    df['rolling_mean'] = df[df.columns[0]].rolling(100).mean()\n",
    "    plt.figure(figsize=(15, 8))\n",
    "    plt.close()\n",
    "    plt.figure()\n",
    "    # plot = df.plot(linewidth=1.5, figsize=(15, 8), title=title)\n",
    "    plot = df.plot(linewidth=1.5, figsize=(15, 8))\n",
    "    plot.set_xlabel(x_axis_label)\n",
    "    plot.set_ylabel(y_axis_label)\n",
    "    # plt.ylim((-400, 300))\n",
    "    fig = plot.get_figure()\n",
    "    plt.legend().set_visible(False)\n",
    "    fig.savefig(chart_name)\n",
    "\n",
    "\n",
    "def plot_df2(df, chart_name, title, x_axis_label, y_axis_label):\n",
    "    df['mean'] = df[df.columns[0]].mean()\n",
    "    plt.rcParams.update({'font.size': 17})\n",
    "    plt.figure(figsize=(15, 8))\n",
    "    plt.close()\n",
    "    plt.figure()\n",
    "    # plot = df.plot(linewidth=1.5, figsize=(15, 8), title=title)\n",
    "    plot = df.plot(linewidth=1.5, figsize=(15, 8))\n",
    "    plot.set_xlabel(x_axis_label)\n",
    "    plot.set_ylabel(y_axis_label)\n",
    "    plt.ylim((0, 300))\n",
    "    plt.xlim((0, 100))\n",
    "    plt.legend().set_visible(False)\n",
    "    fig = plot.get_figure()\n",
    "    fig.savefig(chart_name)\n",
    "\n",
    "\n",
    "def plot_experiments(df, chart_name, title, x_axis_label, y_axis_label, y_limit):\n",
    "    plt.rcParams.update({'font.size': 17})\n",
    "    plt.figure(figsize=(15, 8))\n",
    "    plt.close()\n",
    "    plt.figure()\n",
    "    plot = df.plot(linewidth=1, figsize=(15, 8), title=title)\n",
    "    plot.set_xlabel(x_axis_label)\n",
    "    plot.set_ylabel(y_axis_label)\n",
    "    plt.ylim(y_limit)\n",
    "    fig = plot.get_figure()\n",
    "    fig.savefig(chart_name)\n",
    "\n",
    "\n",
    "def run_experiment_for_gamma():\n",
    "    print('Running Experiment for gamma...')\n",
    "    env = gym.make('LunarLander-v2')\n",
    "\n",
    "    # set seeds\n",
    "    env.seed(21)\n",
    "    np.random.seed(21)\n",
    "\n",
    "    # setting up params\n",
    "    lr = 0.001\n",
    "    epsilon = 1.0\n",
    "    epsilon_decay = 0.995\n",
    "    gamma_list = [0.99, 0.9, 0.8, 0.7]\n",
    "    training_episodes = 1000\n",
    "\n",
    "    rewards_list_for_gammas = []\n",
    "    for gamma_value in gamma_list:\n",
    "        # save_dir = \"hp_gamma_\"+ str(gamma_value) + \"_\"\n",
    "        model = DQN(env, lr, gamma_value, epsilon, epsilon_decay)\n",
    "        print(\"Training model for Gamma: {}\".format(gamma_value))\n",
    "        model.train(training_episodes, False)\n",
    "        rewards_list_for_gammas.append(model.rewards_list)\n",
    "\n",
    "    pickle.dump(rewards_list_for_gammas, open(\"rewards_list_for_gammas.p\", \"wb\"))\n",
    "    rewards_list_for_gammas = pickle.load(open(\"rewards_list_for_gammas.p\", \"rb\"))\n",
    "\n",
    "    gamma_rewards_pd = pd.DataFrame(index=pd.Series(range(1, training_episodes + 1)))\n",
    "    for i in range(len(gamma_list)):\n",
    "        col_name = \"gamma=\" + str(gamma_list[i])\n",
    "        gamma_rewards_pd[col_name] = rewards_list_for_gammas[i]\n",
    "    plot_experiments(gamma_rewards_pd, \"Figure 4: Rewards per episode for different gamma values\",\n",
    "                     \"Figure 4: Rewards per episode for different gamma values\", \"Episodes\", \"Reward\", (-600, 300))\n",
    "\n",
    "\n",
    "def run_experiment_for_lr():\n",
    "    print('Running Experiment for learning rate...')\n",
    "    env = gym.make('LunarLander-v2')\n",
    "\n",
    "    # set seeds\n",
    "    env.seed(21)\n",
    "    np.random.seed(21)\n",
    "\n",
    "    # setting up params\n",
    "    lr_values = [0.0001, 0.001, 0.01, 0.1]\n",
    "    epsilon = 1.0\n",
    "    epsilon_decay = 0.995\n",
    "    gamma = 0.99\n",
    "    training_episodes = 1000\n",
    "    rewards_list_for_lrs = []\n",
    "    for lr_value in lr_values:\n",
    "        model = DQN(env, lr_value, gamma, epsilon, epsilon_decay)\n",
    "        print(\"Training model for LR: {}\".format(lr_value))\n",
    "        model.train(training_episodes, False)\n",
    "        rewards_list_for_lrs.append(model.rewards_list)\n",
    "\n",
    "    pickle.dump(rewards_list_for_lrs, open(\"rewards_list_for_lrs.p\", \"wb\"))\n",
    "    rewards_list_for_lrs = pickle.load(open(\"rewards_list_for_lrs.p\", \"rb\"))\n",
    "\n",
    "    lr_rewards_pd = pd.DataFrame(index=pd.Series(range(1, training_episodes + 1)))\n",
    "    for i in range(len(lr_values)):\n",
    "        col_name = \"lr=\"+ str(lr_values[i])\n",
    "        lr_rewards_pd[col_name] = rewards_list_for_lrs[i]\n",
    "    plot_experiments(lr_rewards_pd, \"Figure 3: Rewards per episode for different learning rates\", \"Figure 3: Rewards per episode for different learning rates\", \"Episodes\", \"Reward\", (-2000, 300))\n",
    "\n",
    "\n",
    "def run_experiment_for_ed():\n",
    "    print('Running Experiment for epsilon decay...')\n",
    "    env = gym.make('LunarLander-v2')\n",
    "\n",
    "    # set seeds\n",
    "    env.seed(21)\n",
    "    np.random.seed(21)\n",
    "\n",
    "    # setting up params\n",
    "    lr = 0.001\n",
    "    epsilon = 1.0\n",
    "    ed_values = [0.999, 0.995, 0.990, 0.9]\n",
    "    gamma = 0.99\n",
    "    training_episodes = 1000\n",
    "\n",
    "    rewards_list_for_ed = []\n",
    "    for ed in ed_values:\n",
    "        save_dir = \"hp_ed_\"+ str(ed) + \"_\"\n",
    "        model = DQN(env, lr, gamma, epsilon, ed)\n",
    "        print(\"Training model for ED: {}\".format(ed))\n",
    "        model.train(training_episodes, False)\n",
    "        rewards_list_for_ed.append(model.rewards_list)\n",
    "\n",
    "    pickle.dump(rewards_list_for_ed, open(\"rewards_list_for_ed.p\", \"wb\"))\n",
    "    rewards_list_for_ed = pickle.load(open(\"rewards_list_for_ed.p\", \"rb\"))\n",
    "\n",
    "    ed_rewards_pd = pd.DataFrame(index=pd.Series(range(1, training_episodes+1)))\n",
    "    for i in range(len(ed_values)):\n",
    "        col_name = \"epsilon_decay = \"+ str(ed_values[i])\n",
    "        ed_rewards_pd[col_name] = rewards_list_for_ed[i]\n",
    "    plot_experiments(ed_rewards_pd, \"Figure 5: Rewards per episode for different epsilon(ε) decay\", \"Figure 5: Rewards per episode for different epsilon(ε) decay values\", \"Episodes\", \"Reward\", (-600, 300))\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    env = gym.make('LunarLander-v2')\n",
    "\n",
    "    # set seeds\n",
    "    env.seed(21)\n",
    "    np.random.seed(21)\n",
    "\n",
    "    # setting up params\n",
    "    lr = 0.001\n",
    "    epsilon = 1.0\n",
    "    epsilon_decay = 0.995\n",
    "    gamma = 0.99\n",
    "    training_episodes = 2000\n",
    "    print('St')\n",
    "    model = DQN(env, lr, gamma, epsilon, epsilon_decay)\n",
    "    model.train(training_episodes, True)\n",
    "\n",
    "    # Save Everything\n",
    "    save_dir = \"saved_models\"\n",
    "    # Save trained model\n",
    "    model.save(save_dir + \"trained_model.h5\")\n",
    "\n",
    "    # Save Rewards list\n",
    "    pickle.dump(model.rewards_list, open(save_dir + \"train_rewards_list.p\", \"wb\"))\n",
    "    rewards_list = pickle.load(open(save_dir + \"train_rewards_list.p\", \"rb\"))\n",
    "\n",
    "    # plot reward in graph\n",
    "    reward_df = pd.DataFrame(rewards_list)\n",
    "    plot_df(reward_df, \"Figure 1: Reward for each training episode\", \"Reward for each training episode\", \"Episode\",\"Reward\")\n",
    "\n",
    "    # Test the model\n",
    "    trained_model = load_model(save_dir + \"trained_model.h5\")\n",
    "    test_rewards = test_already_trained_model(trained_model)\n",
    "    pickle.dump(test_rewards, open(save_dir + \"test_rewards.p\", \"wb\"))\n",
    "    test_rewards = pickle.load(open(save_dir + \"test_rewards.p\", \"rb\"))\n",
    "\n",
    "    plot_df2(pd.DataFrame(test_rewards), \"Figure 2: Reward for each testing episode\",\"Reward for each testing episode\", \"Episode\", \"Reward\")\n",
    "    print(\"Training and Testing Completed...!\")\n",
    "\n",
    "    # Run experiments for hyper-parameter\n",
    "    run_experiment_for_lr()\n",
    "    run_experiment_for_ed()\n",
    "    run_experiment_for_gamma()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
